#!/usr/bin/env python3
"""æ€§èƒ½åŸºå‡†æµ‹è¯•."""

import asyncio
import statistics
import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from codemux.command_router import CommandRouter
from codemux.output_processor import OutputProcessor
from codemux.tmux_controller import TmuxController
from rich.console import Console
from rich.table import Table


async def benchmark_commands():
    """å‘½ä»¤æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•."""
    console = Console()
    console.print("ğŸ [bold blue]Codemux æ€§èƒ½åŸºå‡†æµ‹è¯•[/bold blue]\n")

    tmux = TmuxController()
    processor = OutputProcessor(tmux)
    router = CommandRouter(tmux, processor)

    sessions = tmux.discover_claude_sessions()
    router.update_sessions(sessions)

    if not sessions:
        console.print("âŒ æœªå‘ç°ä¼šè¯")
        return False

    # åŸºå‡†æµ‹è¯•ç”¨ä¾‹
    benchmarks = [
        {"name": "ä¼šè¯å‘ç°", "func": lambda: tmux.discover_claude_sessions()},
        {"name": "çŠ¶æ€æŸ¥è¯¢", "func": lambda: router.handle_status_query()},
        {
            "name": "ä¼šè¯åˆ‡æ¢",
            "func": lambda: asyncio.run(router.handle_session_command("frontend", "")),
        },
        {
            "name": "ç®€å•å‘½ä»¤",
            "func": lambda: asyncio.run(router.route_command("#frontend pwd")),
        },
    ]

    results = {}

    for benchmark in benchmarks:
        console.print(f"ğŸƒ æµ‹è¯•: {benchmark['name']}")
        times = []

        # æ¯ä¸ªæµ‹è¯•è¿è¡Œ 5 æ¬¡
        for i in range(5):
            start = time.time()
            try:
                result = benchmark["func"]()
                if asyncio.iscoroutine(result):
                    await result
            except Exception as e:
                console.print(f"  âŒ è¿è¡Œ {i+1} å¤±è´¥: {e}")
                continue
            end = time.time()

            execution_time = (end - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            times.append(execution_time)
            console.print(f"  è¿è¡Œ {i+1}: {execution_time:.1f}ms")

        if times:
            results[benchmark["name"]] = {
                "min": min(times),
                "max": max(times),
                "avg": statistics.mean(times),
                "median": statistics.median(times),
            }

    # æ˜¾ç¤ºåŸºå‡†æµ‹è¯•ç»“æœ
    console.print("\nğŸ“Š [bold cyan]æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ[/bold cyan]")
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("æµ‹è¯•é¡¹ç›®", style="cyan")
    table.add_column("æœ€å°å€¼ (ms)", style="green")
    table.add_column("æœ€å¤§å€¼ (ms)", style="red")
    table.add_column("å¹³å‡å€¼ (ms)", style="yellow")
    table.add_column("ä¸­ä½æ•° (ms)", style="blue")

    for name, stats in results.items():
        table.add_row(
            name,
            f"{stats['min']:.1f}",
            f"{stats['max']:.1f}",
            f"{stats['avg']:.1f}",
            f"{stats['median']:.1f}",
        )

    console.print(table)

    # æ€§èƒ½è¯„ä¼°
    console.print("\nğŸ¯ [bold green]æ€§èƒ½è¯„ä¼°[/bold green]")

    benchmarks_check = [
        ("ä¼šè¯å‘ç°", "avg", 2000, "ä¼šè¯å‘ç°åº”åœ¨ 2s å†…å®Œæˆ"),
        ("çŠ¶æ€æŸ¥è¯¢", "avg", 100, "çŠ¶æ€æŸ¥è¯¢åº”åœ¨ 100ms å†…å®Œæˆ"),
        ("ä¼šè¯åˆ‡æ¢", "avg", 200, "ä¼šè¯åˆ‡æ¢åº”åœ¨ 200ms å†…å®Œæˆ"),
        ("ç®€å•å‘½ä»¤", "avg", 5000, "ç®€å•å‘½ä»¤åº”åœ¨ 5s å†…å®Œæˆ"),
    ]

    all_passed = True
    for name, metric, threshold, description in benchmarks_check:
        if name in results:
            value = results[name][metric]
            if value <= threshold:
                console.print(f"âœ… {description}: {value:.1f}ms (ç›®æ ‡: â‰¤{threshold}ms)")
            else:
                console.print(f"âš ï¸ {description}: {value:.1f}ms (ç›®æ ‡: â‰¤{threshold}ms)")
                all_passed = False

    return all_passed


if __name__ == "__main__":
    try:
        success = asyncio.run(benchmark_commands())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(1)
